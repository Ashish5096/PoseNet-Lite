{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legislative-palestine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tflite_runtime.interpreter as tflite\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "registered-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worthy-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_tensor(interpreter, index):\n",
    "\n",
    "    output_details = interpreter.get_output_details()[index]\n",
    "    tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "protecting-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_tensor(interpreter, image):\n",
    "    tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    input_tensor = interpreter.tensor(tensor_index)()[0]\n",
    "    input_tensor[:, :] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incomplete-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInputImageDimensions(image):\n",
    "    \n",
    "    return image.shape[0],image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cloudy-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x,k):\n",
    "    \n",
    "     return 1 / (1 + np.exp(-x/k));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rocky-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPointsConfidence(heatmap_scores,heatmap_coords):\n",
    "    \n",
    "    numKeyPoints = heatmap_coords.shape[0]\n",
    "    result = []\n",
    "    \n",
    "    for keypoint in range(0, numKeyPoints):\n",
    "        y = heatmap_coords[keypoint][0]\n",
    "        x = heatmap_coords[keypoint][1]\n",
    "        result.append(heatmap_scores[y][x][keypoint])\n",
    "    \n",
    "    result = np.array(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legislative-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOffsetPoints(heatmapCoords,offset,img_height, img_width):\n",
    "    \n",
    "    numKeyPoints = heatmapCoords.shape[0]\n",
    "    result =[]\n",
    "    \n",
    "    for keypoint in range(0,numKeyPoints):\n",
    "        heatmapY = heatmapCoords[keypoint][0]\n",
    "        heatmapX = heatmapCoords[keypoint][1]\n",
    "        y = int((heatmapY*img_height)/8 + offset[heatmapY][heatmapX][keypoint])\n",
    "        x = int((heatmapX*img_width)/8 + offset[heatmapY][heatmapX][keypoint+ numKeyPoints])        \n",
    "        result.append((y,x))\n",
    "    \n",
    "    result = np.array(result)  #shape(17,2)  \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "invalid-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_poses(interpreter, image,input_resolution):\n",
    "    \n",
    "    flip_horizontal = False\n",
    "    \n",
    "    img_height, img_width = getInputImageDimensions(image)\n",
    "    resized = cv2.resize(image,(input_resolution[0], input_resolution[1]))\n",
    "    \n",
    "    #model posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite runs from -1.0 ... +1.0\n",
    "    resized = (resized -127.5)/127.5\n",
    "    \n",
    "    set_input_tensor(interpreter, resized)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    # Get all output details\n",
    "    heatmap = get_output_tensor(interpreter,0)   #shape: (9,9,17)\n",
    "    offset = get_output_tensor(interpreter,1)    #shape: (9,9,34)\n",
    "    #heatmap = sigmoid(heatmap,1)                       \n",
    "    \n",
    "    height, width, depth = heatmap.shape\n",
    "    reshaped = heatmap.reshape(height*width,depth)   #shape: (81,17)\n",
    "    coords = np.argmax(reshaped,0)\n",
    "    ycoords = coords//width\n",
    "    xcoords = coords%width\n",
    "\n",
    "    heatmap_coords=[]\n",
    "    for i in range(0,17):\n",
    "        heatmap_coords.append((ycoords[i],xcoords[i]))\n",
    "    heatmap_coords = np.array(heatmap_coords) #shape: (17,2)\n",
    "    \n",
    "    keypoint_confidence = getPointsConfidence(heatmap,heatmap_coords)\n",
    "    keypoint_confidence = sigmoid(keypoint_confidence,1)\n",
    "    keypoints =  getOffsetPoints(heatmap_coords,offset,img_height, img_width)\n",
    "    \n",
    "    result_keypoints =[]\n",
    "    for i in range(0,len(keypoints)):\n",
    "            result_keypoints.append((int(keypoints[i][1]),int(keypoints[i][0])))\n",
    "    \n",
    "    return result_keypoints,keypoint_confidence       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afraid-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPoint(img,center,radius):\n",
    "\n",
    "    thickness =-1\n",
    "    color = (0, 255, 0)\n",
    "    img = cv2.circle(img, center, radius, color, thickness)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "separated-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.8;    \n",
    "\n",
    "def drawKeypoints(img, k_coords, k_conf):\n",
    "    \n",
    "    n =len(k_coords)\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        if(k_conf[i]> confidence_threshold):\n",
    "            drawPoint(img,k_coords[i],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecological-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLine(img,start_point, end_point, thickness):\n",
    "\n",
    "    color = (0, 255, 0)\n",
    "    img = cv2.line(img, start_point, end_point, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suitable-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.8    \n",
    "\n",
    "def drawSkeleton(img, k_coords,k_conf):\n",
    "    \n",
    "    if(k_conf[ 5]>confidence_threshold):\n",
    "        if(k_conf[6]>confidence_threshold):\n",
    "            drawLine(img,k_coords[ 5],k_coords[ 6],2)\n",
    "        if(k_conf[7]>confidence_threshold):\n",
    "            drawLine(img,k_coords[ 5],k_coords[ 7],2)\n",
    "        if(k_conf[11]>confidence_threshold):\n",
    "            drawLine(img,k_coords[ 5],k_coords[11],2)\n",
    "    \n",
    "    if(k_conf[ 6]>confidence_threshold):\n",
    "        if(k_conf[8]>confidence_threshold):  drawLine(img,k_coords[6],k_coords[ 8],2)\n",
    "        if(k_conf[12]>confidence_threshold): drawLine(img,k_coords[6],k_coords[12],2)\n",
    "    \n",
    "    if(k_conf[7]>confidence_threshold):\n",
    "        if(k_conf[9]>confidence_threshold):  drawLine(img,k_coords[7],k_coords[9],2)\n",
    "    \n",
    "    if(k_conf[ 8]>confidence_threshold):\n",
    "        if(k_conf[10]>confidence_threshold): drawLine(img,k_coords[ 8],k_coords[10],2);\n",
    "    \n",
    "    if(k_conf[11]>confidence_threshold):\n",
    "        if(k_conf[12]>confidence_threshold): drawLine(img,k_coords[11],k_coords[12],2);\n",
    "        if(k_conf[13]>confidence_threshold): drawLine(img,k_coords[11],k_coords[13],2);\n",
    "    \n",
    "    if(k_conf[13]>confidence_threshold):\n",
    "        if(k_conf[15]>confidence_threshold): drawLine(img,k_coords[13],k_coords[15],2)\n",
    "    \n",
    "    if(k_conf[14]>confidence_threshold):\n",
    "        if(k_conf[12]>confidence_threshold): drawLine(img,k_coords[14],k_coords[12],2)\n",
    "        if(k_conf[16]>confidence_threshold): drawLine(img,k_coords[14],k_coords[16],2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "second-behalf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99420434 0.991954   0.89997613 0.9356845  0.10531113 0.9914641\n",
      " 0.9810146  0.9926959  0.9692133  0.9068489  0.90729076 0.9932314\n",
      " 0.982566   0.92077124 0.895883   0.8823035  0.9636957 ]\n"
     ]
    }
   ],
   "source": [
    "def Pose_image():\n",
    "    _, input_height, input_width,channels = interpreter.get_input_details()[0]['shape']\n",
    "    \n",
    "    \n",
    "    image = cv2.imread('image_2.jpg',1)\n",
    "    keypoints, keypoint_confidence = detect_poses(interpreter,image,(input_width,input_height))\n",
    "    \n",
    "    #print(keypoint_confidence)\n",
    "    drawKeypoints(image,keypoints,keypoint_confidence)\n",
    "    drawSkeleton(image,keypoints,keypoint_confidence)\n",
    "    cv2.imshow(\"Pose\",image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "Gait()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedicated-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pose_video():\n",
    "    \n",
    "    _, input_height, input_width,channels = interpreter.get_input_details()[0]['shape']\n",
    "    vid = cv2.VideoCapture(0)\n",
    "    \n",
    "    fps=0\n",
    "    \n",
    "    while(True):\n",
    "        fps_start_time = time.time()\n",
    "        \n",
    "        ret, image = vid.read() \n",
    "        \n",
    "        keypoints, keypoint_confidence = detect_poses(interpreter,image,(input_height, input_width))\n",
    "        drawKeypoints(image,keypoints,keypoint_confidence)\n",
    "        drawSkeleton(image,keypoints,keypoint_confidence)\n",
    "        \n",
    "        time_diff = time.time() - fps_start_time\n",
    "        \n",
    "        if(time_diff ==0):\n",
    "            fps =0\n",
    "        else:\n",
    "            fps = 1/ time_diff\n",
    "            \n",
    "        fps_text = \"FPS {:.2f}\".format(fps)\n",
    "        cv2.putText(image,fps_text,(5,30),cv2.FONT_HERSHEY_SIMPLEX,1,(255, 0, 0),1)\n",
    "        cv2.imshow('Pose', image) \n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "  \n",
    "    vid.release() \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "Gait_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-reporter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
